{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3bab8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici on compare la méthode implémentée sur tensorflow à la méthode déja existante de la library kornia\n",
    "\n",
    "# Kornia : \n",
    "\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "# Version kornia\n",
    "# version kornia\n",
    "import torch.nn.functional\n",
    "\n",
    "def convert_points_to_homogeneous(points):\n",
    "    r\"\"\"Function that converts points from Euclidean to homogeneous space.\n",
    "\n",
    "    See :class:`~torchgeometry.ConvertPointsToHomogeneous` for details.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> input = torch.rand(2, 4, 3)  # BxNx3\n",
    "        >>> output = tgm.convert_points_to_homogeneous(input)  # BxNx4\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(points):\n",
    "        raise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(\n",
    "            type(points)))\n",
    "    if len(points.shape) < 2:\n",
    "        raise ValueError(\"Input must be at least a 2D tensor. Got {}\".format(\n",
    "            points.shape))\n",
    "\n",
    "    return torch.nn.functional.pad(points, (0, 1), \"constant\", 1.0)\n",
    "def symmetrical_epipolar_distance(\n",
    "    pts1: torch.Tensor, pts2: torch.Tensor, Fm: torch.Tensor, squared: bool = True, eps: float = 1e-8\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Return symmetrical epipolar distance for correspondences given the fundamental matrix.\n",
    "\n",
    "    Args:\n",
    "       pts1: correspondences from the left images with shape\n",
    "         (B, N, 2 or 3). If they are not homogeneous, converted automatically.\n",
    "       pts2: correspondences from the right images with shape\n",
    "         (B, N, 2 or 3). If they are not homogeneous, converted automatically.\n",
    "       Fm: Fundamental matrices with shape :math:`(B, 3, 3)`. Called Fm to\n",
    "         avoid ambiguity with torch.nn.functional.\n",
    "       squared: if True (default), the squared distance is returned.\n",
    "       eps: Small constant for safe sqrt.\n",
    "\n",
    "    Returns:\n",
    "        the computed Symmetrical distance with shape :math:`(B, N)`.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(Fm, torch.Tensor):\n",
    "        raise TypeError(f\"Fm type is not a torch.Tensor. Got {type(Fm)}\")\n",
    "\n",
    "    if (len(Fm.shape) != 3) or not Fm.shape[-2:] == (3, 3):\n",
    "        raise ValueError(f\"Fm must be a (*, 3, 3) tensor. Got {Fm.shape}\")\n",
    "\n",
    "    if pts1.size(-1) == 2:\n",
    "        pts1 = convert_points_to_homogeneous(pts1)\n",
    "\n",
    "    if pts2.size(-1) == 2:\n",
    "        pts2 = convert_points_to_homogeneous(pts2)\n",
    "\n",
    "    # From Hartley and Zisserman, symmetric epipolar distance (11.10)\n",
    "    # sed = (x'^T F x) ** 2 /  (((Fx)_1**2) + (Fx)_2**2)) +  1/ (((F^Tx')_1**2) + (F^Tx')_2**2))\n",
    "\n",
    "    # line1_in_2: torch.Tensor = (F @ pts1.permute(0,2,1)).permute(0,2,1)\n",
    "    # line2_in_1: torch.Tensor = (F.permute(0,2,1) @ pts2.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "    # Instead we can just transpose F once and switch the order of multiplication\n",
    "    F_t: torch.Tensor = Fm.permute(0, 2, 1)\n",
    "    line1_in_2: torch.Tensor = pts1 @ F_t\n",
    "    line2_in_1: torch.Tensor = pts2 @ Fm\n",
    "\n",
    "    # numerator = (x'^T F x) ** 2\n",
    "    numerator: torch.Tensor = (pts2 * line1_in_2).sum(2).pow(2)\n",
    "\n",
    "    # denominator_inv =  1/ (((Fx)_1**2) + (Fx)_2**2)) +  1/ (((F^Tx')_1**2) + (F^Tx')_2**2))\n",
    "    denominator_inv: torch.Tensor = 1.0 / (line1_in_2[..., :2].norm(2, dim=2).pow(2)) + 1.0 / (\n",
    "        line2_in_1[..., :2].norm(2, dim=2).pow(2)\n",
    "    )\n",
    "    out: torch.Tensor = numerator * denominator_inv\n",
    "    if squared:\n",
    "        return out\n",
    "    return (out + eps).sqrt()\n",
    "\n",
    "\n",
    "def fundamental_from_projections(P1: torch.Tensor, P2: torch.Tensor) -> torch.Tensor:\n",
    "    r\"\"\"Get the Fundamental matrix from Projection matrices.\n",
    "\n",
    "    Args:\n",
    "        P1: The projection matrix from first camera with shape :math:`(*, 3, 4)`.\n",
    "        P2: The projection matrix from second camera with shape :math:`(*, 3, 4)`.\n",
    "\n",
    "    Returns:\n",
    "         The fundamental matrix with shape :math:`(*, 3, 3)`.\n",
    "\n",
    "    \"\"\"\n",
    "    def vstack(x, y):\n",
    "        return torch.cat([x, y], dim=-2)\n",
    "    X1 = P1[..., 1:, :]\n",
    "    X2 = vstack(P1[..., 2:3, :], P1[..., 0:1, :])\n",
    "    X3 = P1[..., :2, :]\n",
    "\n",
    "    Y1 = P2[..., 1:, :]\n",
    "    Y2 = vstack(P2[..., 2:3, :], P2[..., 0:1, :])\n",
    "    Y3 = P2[..., :2, :]\n",
    "\n",
    "    X1Y1, X2Y1, X3Y1 = vstack(X1, Y1), vstack(X2, Y1), vstack(X3, Y1)\n",
    "    X1Y2, X2Y2, X3Y2 = vstack(X1, Y2), vstack(X2, Y2), vstack(X3, Y2)\n",
    "    X1Y3, X2Y3, X3Y3 = vstack(X1, Y3), vstack(X2, Y3), vstack(X3, Y3)\n",
    "    F_vec = torch.cat(\n",
    "        [\n",
    "            X1Y1.det().reshape(-1, 1),\n",
    "            X2Y1.det().reshape(-1, 1),\n",
    "            X3Y1.det().reshape(-1, 1),\n",
    "            X1Y2.det().reshape(-1, 1),\n",
    "            X2Y2.det().reshape(-1, 1),\n",
    "            X3Y2.det().reshape(-1, 1),\n",
    "            X1Y3.det().reshape(-1, 1),\n",
    "            X2Y3.det().reshape(-1, 1),\n",
    "            X3Y3.det().reshape(-1, 1),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    return F_vec.view(*P1.shape[:-2], 3, 3)\n",
    "\n",
    "\n",
    "def triangulate_points(\n",
    "    P1: torch.Tensor, P2: torch.Tensor, points1: torch.Tensor, points2: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Reconstructs a bunch of points by triangulation.\n",
    "\n",
    "    Triangulates the 3d position of 2d correspondences between several images.\n",
    "    Reference: Internally it uses DLT method from Hartley/Zisserman 12.2 pag.312\n",
    "\n",
    "    The input points are assumed to be in homogeneous coordinate system and being inliers\n",
    "    correspondences. The method does not perform any robust estimation.\n",
    "\n",
    "    Args:\n",
    "        P1: The projection matrix for the first camera with shape :math:`(*, 3, 4)`.\n",
    "        P2: The projection matrix for the second camera with shape :math:`(*, 3, 4)`.\n",
    "        points1: The set of points seen from the first camera frame in the camera plane\n",
    "          coordinates with shape :math:`(*, N, 2)`.\n",
    "        points2: The set of points seen from the second camera frame in the camera plane\n",
    "          coordinates with shape :math:`(*, N, 2)`.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed 3d points in the world frame with shape :math:`(*, N, 3)`.\n",
    "\n",
    "    \"\"\"\n",
    "    if not (len(P1.shape) >= 2 and P1.shape[-2:] == (3, 4)):\n",
    "        raise AssertionError(P1.shape)\n",
    "    if not (len(P2.shape) >= 2 and P2.shape[-2:] == (3, 4)):\n",
    "        raise AssertionError(P2.shape)\n",
    "    if len(P1.shape[:-2]) != len(P2.shape[:-2]):\n",
    "        raise AssertionError(P1.shape, P2.shape)\n",
    "    if not (len(points1.shape) >= 2 and points1.shape[-1] == 2):\n",
    "        raise AssertionError(points1.shape)\n",
    "    if not (len(points2.shape) >= 2 and points2.shape[-1] == 2):\n",
    "        raise AssertionError(points2.shape)\n",
    "    if len(points1.shape[:-2]) != len(points2.shape[:-2]):\n",
    "        raise AssertionError(points1.shape, points2.shape)\n",
    "    if len(P1.shape[:-2]) != len(points1.shape[:-2]):\n",
    "        raise AssertionError(P1.shape, points1.shape)\n",
    "\n",
    "    # allocate and construct the equations matrix with shape (*, 4, 4)\n",
    "    points_shape = max(points1.shape, points2.shape)  # this allows broadcasting\n",
    "    X = torch.zeros(points_shape[:-1] + (4, 4)).type_as(points1)\n",
    "\n",
    "    for i in range(4):\n",
    "        X[..., 0, i] = points1[..., 0] * P1[..., 2:3, i] - P1[..., 0:1, i]\n",
    "        X[..., 1, i] = points1[..., 1] * P1[..., 2:3, i] - P1[..., 1:2, i]\n",
    "        X[..., 2, i] = points2[..., 0] * P2[..., 2:3, i] - P2[..., 0:1, i]\n",
    "        X[..., 3, i] = points2[..., 1] * P2[..., 2:3, i] - P2[..., 1:2, i]\n",
    "\n",
    "    # 1. Solve the system Ax=0 with smallest eigenvalue\n",
    "    # 2. Return homogeneous coordinates\n",
    "\n",
    "    _, _, V = torch.svd(X)\n",
    "\n",
    "    points3d_h = V[..., -1]\n",
    "    points3d: torch.Tensor = convert_points_from_homogeneous(points3d_h)\n",
    "    return points3d\n",
    "\n",
    "\n",
    "def convert_points_from_homogeneous(points: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    r\"\"\"Function that converts points from homogeneous to Euclidean space.\n",
    "\n",
    "    Args:\n",
    "        points: the points to be transformed of shape :math:`(B, N, D)`.\n",
    "        eps: to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        the points in Euclidean space :math:`(B, N, D-1)`.\n",
    "\n",
    "    Examples:\n",
    "        >>> input = torch.tensor([[0., 0., 1.]])\n",
    "        >>> convert_points_from_homogeneous(input)\n",
    "        tensor([[0., 0.]])\n",
    "    \"\"\"\n",
    "    if not isinstance(points, torch.Tensor):\n",
    "        raise TypeError(f\"Input type is not a torch.Tensor. Got {type(points)}\")\n",
    "\n",
    "    if len(points.shape) < 2:\n",
    "        raise ValueError(f\"Input must be at least a 2D tensor. Got {points.shape}\")\n",
    "\n",
    "    # we check for points at max_val\n",
    "    z_vec: torch.Tensor = points[..., -1:]\n",
    "\n",
    "    # set the results of division by zeror/near-zero to 1.0\n",
    "    # follow the convention of opencv:\n",
    "    # https://github.com/opencv/opencv/pull/14411/files\n",
    "    mask: torch.Tensor = torch.abs(z_vec) > eps\n",
    "    scale = torch.where(mask, 1.0 / (z_vec + eps), torch.ones_like(z_vec))\n",
    "\n",
    "    return scale * points[..., :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7b6d7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "P2t=torch.tensor([[162.36,-438.34,-17.508,3347.4],[73.3,-10.043,-443.34,1373.5],[0.99035,-0.047887,-0.13009,6.6849]])\n",
    "P1t=torch.tensor([[439.0,180.81,-26.946,185.95],[-5.3416,88.523,-450.95,1324],[0.0060594,0.99348,-0.11385,5.227]])\n",
    "ft=fundamental_from_projections(P1t,P2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "342d98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre méthode\n",
    "\n",
    "# Version tensoflow\n",
    "\n",
    "# version tf\n",
    "\n",
    "def convert_points_to_homogeneous(points):\n",
    "    \"\"\"Function that converts points from Euclidean to homogeneous space.\n",
    "\n",
    "    See :class:`~torchgeometry.ConvertPointsToHomogeneous` for details.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> input = torch.rand(2, 4, 3)  # BxNx3\n",
    "        >>> output = tgm.convert_points_to_homogeneous(input)  # BxNx4\n",
    "    \"\"\"\n",
    "    if not tf.is_tensor(points):\n",
    "        raise TypeError(\"Input type is not a tf.Tensor. Got {}\".format(\n",
    "            type(points)))\n",
    "    if len(points.shape) < 2:\n",
    "        raise ValueError(\"Input must be at least a 2D tensor. Got {}\".format(\n",
    "            points.shape))\n",
    "    paddings = tf.constant([[0,0], [0,1]])\n",
    "    \n",
    "    return tf.pad(points, paddings, mode='CONSTANT', constant_values=1)\n",
    "\n",
    "\n",
    "def tf_symmetrical_epipolar_distance(pts1,pts2,Fm, squared, eps) : \n",
    "    \"\"\"\n",
    "    Return symmetrical epipolar distance for correspondences given the fundamental matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(Fm, tf.Tensor):\n",
    "        raise TypeError(f\"Fm type is not a torch.Tensor. Got {type(Fm)}\")\n",
    "\n",
    "    if (len(Fm.shape) != 3) or not Fm.shape[-2:] == (3, 3):\n",
    "        raise ValueError(f\"Fm must be a (*, 3, 3) tensor. Got {Fm.shape}\")\n",
    "\n",
    "        ###########Acompleter\n",
    "    if pts1.size(-1) == 2:\n",
    "        pts1 = convert_points_to_homogeneous(pts1)\n",
    "\n",
    "    if pts2.size(-1) == 2:\n",
    "        pts2 = convert_points_to_homogeneous(pts2)\n",
    "\n",
    "    # From Hartley and Zisserman, symmetric epipolar distance (11.10)\n",
    "    # sed = (x'^T F x) ** 2 /  (((Fx)_1**2) + (Fx)_2**2)) +  1/ (((F^Tx')_1**2) + (F^Tx')_2**2))\n",
    "    # Instead we can just transpose F once and switch the order of multiplication\n",
    "    \n",
    "    F_t = tf.transpose(Fm, perm=(0,2,1), conjugate=False, name='permute')\n",
    "    line1_in_2 = pts1 @ F_t\n",
    "    line2_in_1 = pts2 @ Fm\n",
    "\n",
    "    # numerator = (x'^T F x) ** 2\n",
    "    #numerator  = (pts2 * line1_in_2).sum(2).pow(2)\n",
    "    numerator  = tf.pow(tf.math.reduce_sum((pts2 * line1_in_2),2),2)\n",
    "\n",
    "\n",
    "    # denominator_inv =  1/ (((Fx)_1**2) + (Fx)_2**2)) +  1/ (((F^Tx')_1**2) + (F^Tx')_2**2))\n",
    "    denominator_inv = 1.0 / (line1_in_2[..., :2].norm(2, dim=2).pow(2)) + 1.0 / (\n",
    "        line2_in_1[..., :2].norm(2, dim=2).pow(2)\n",
    "    )\n",
    "    \n",
    "    denominator_inv = 1.0 / (tf.pow(tf.norm(line1_in_2[..., :2],axis=2),2)) + 1.0 / (\n",
    "        tf.pow(tf.norm(line2_in_1[..., :2],axis=2),2)\n",
    "    )\n",
    "    \n",
    "    out = numerator * denominator_inv\n",
    "    if squared:\n",
    "        return out\n",
    "    return tf.math.sqrt(out + eps)\n",
    "\n",
    "def fundamental_matrix_from_projections(P1, P2):\n",
    "    \"\"\"\n",
    "    Get the Fundamental matrix from Projection matrices.\n",
    "    Adapted from \n",
    "    [\n",
    "    https://kornia.readthedocs.io/en/latest/_modules/kornia/\n",
    "    geometry/epipolar/fundamental.html\n",
    "    ]\n",
    "    \"\"\"\n",
    "    if not (len(P1.shape) >= 2 and P1.shape[-2:] == (3, 4)):\n",
    "        raise AssertionError(P1.shape)\n",
    "    if not (len(P2.shape) >= 2 and P2.shape[-2:] == (3, 4)):\n",
    "        raise AssertionError(P2.shape)\n",
    "    if P1.shape[:-2] != P2.shape[:-2]:\n",
    "        raise AssertionError\n",
    "\n",
    "    def vstack(x, y):\n",
    "            return tf.concat([x,y], axis=0, name='concat')\n",
    "    X1 = P1[..., 1:, :]\n",
    "    X2 = vstack(P1[..., 2:3, :], P1[..., 0:1, :])\n",
    "    X3 = P1[..., :2, :]\n",
    "\n",
    "    Y1 = P2[..., 1:, :]\n",
    "    Y2 = vstack(P2[..., 2:3, :], P2[..., 0:1, :])\n",
    "    Y3 = P2[..., :2, :]\n",
    "\n",
    "    X1Y1, X2Y1, X3Y1 = vstack(X1, Y1), vstack(X2, Y1), vstack(X3, Y1)\n",
    "    X1Y2, X2Y2, X3Y2 = vstack(X1, Y2), vstack(X2, Y2), vstack(X3, Y2)\n",
    "    X1Y3, X2Y3, X3Y3 = vstack(X1, Y3), vstack(X2, Y3), vstack(X3, Y3)\n",
    "    F_vec = tf.concat(\n",
    "        [\n",
    "            tf.reshape(tf.linalg.det(X1Y1),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X2Y1),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X3Y1),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X1Y2),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X2Y2),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X3Y2),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X1Y3),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X2Y3),shape=(-1,1)),\n",
    "            tf.reshape(tf.linalg.det(X3Y3),shape=(-1,1)),\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    return tf.reshape(F_vec,shape=(*P1.shape[:-2],3,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022b74c",
   "metadata": {},
   "source": [
    "### Test avec 2 cameras  de campus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88810bb1",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "571ac2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 1.4732189e+08, -7.4190259e+08,  9.2751159e+10]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Projection matrix Camera 2\n",
    "P2=tf.constant([[162.36,-438.34,-17.508,3347.4],[73.3,-10.043,-443.34,1373.5],[0.99035,-0.047887,-0.13009,6.6849]])\n",
    "# Projection matrix Camera 1\n",
    "P1=tf.constant([[439.0,180.81,-26.946,185.95],[-5.3416,88.523,-450.95,1324],[0.0060594,0.99348,-0.11385,5.227]])\n",
    "# Fundamental matrix \n",
    "F1=fundamental_matrix_from_projections(P1,P2)\n",
    "# un point 3D issu de actorGT.mat\n",
    "X=tf.constant([[2.9872, 4.0063, 0.1581]],dtype=tf.float64)\n",
    "# 2 points 2D des deux cameras (issus de actor_2D_GT)\n",
    "x1=tf.constant([[240.8343121],[172.8411121],[  1.0000]])\n",
    "x2=tf.constant([[219.8642],[157.1583],[  1.0000]])\n",
    "interm = tf.linalg.matmul(tf.transpose(x2, perm=(1,0)),F1)\n",
    "interm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58107d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[240.8343 ],\n",
       "       [172.84111],\n",
       "       [  1.     ]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d36f2b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[57344.]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_zero = tf.linalg.matmul(interm,x1)\n",
    "is_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31954ec",
   "metadata": {},
   "source": [
    "### Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31cffcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9872, 4.0063, 0.1581]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point_2t=torch.tensor([[220,158]]) # camera 2 projection\n",
    "Point_1t=torch.tensor([[241.,172.]]) # camera 1 projection\n",
    "kkk=triangulate_points(P1t,P2t,Point_1t,Point_2t) # 3d by triangulation\n",
    "kkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e8a9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=convert_points_to_homogeneous(kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7cb270ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  On calcule  les points 2D  cette fois-ci  \n",
    "# L'erreur vient pttre de la\n",
    "a2=torch.mm(P2t,torch.transpose(kk, 0, 1))\n",
    "a1=torch.mm(P1t,torch.transpose(kk, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "befffb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[240.8343],\n",
       "        [172.8411],\n",
       "        [  1.0000]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1/a1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d834c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[219.8642],\n",
       "        [157.1583],\n",
       "        [  1.0000]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2/a2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b6c45aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2074e+04,  1.5901e+06, -1.4935e+08],\n",
       "        [ 1.9150e+06,  6.7462e+04,  3.0550e+08],\n",
       "        [-1.5098e+08, -1.1021e+09,  7.7577e+10]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b0cbb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.5458e+09]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interm=torch.matmul(torch.transpose(a2/a2[2], 0, 1),ft)\n",
    "torch.matmul(jj,a1/a1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733fb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
